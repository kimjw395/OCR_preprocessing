import sys, os
#sys.path.append('/usr/local/lib/python3.7/site-packages')
import numpy as np
#sys.path.append('/usr/local/lib/python3.7/site-packages/cv2')
import cv2
from sys import argv
from pathlib import Path
#from bottle import route, run, template
import time
#-*- coding: utf-8 -*-

# 디버깅 모드 여부 - 운영 적용시 반드시 False로 전환
DEBUG = True

# 칼라 양식지 여부 판단 변수
IS_COLORED_FORMAT = False

# 이미지의 평균 칼라값(R, G, B)의 합이 675 이상이면 Contrast 적용
CONTRAST_COLOR_BASE = 675

# 이미지의 평균 색깔 합
COLOR_AVG_SUM = 0

# 파란색 계열의 픽셀 수가 10개 이상이면 칼라 양식지로 판단함
COLORED_PIXEL_COUNT = 10

# 파란색 계열 HSV 칼라
LOWER_RANGE = np.array([ 90,  70, 120])
UPPER_RANGE = np.array([150, 150, 200])

# Google Vision API가 글자를 인식가능한 이미지의 최소 너비
MIN_WIDTH = 1500

DIRPATH = ""
FILENAME = ""
EXTENSION = ""

LOG_INDEX = 0

#########################################################################################################################################
#@route('/cvt/<fileName>/<type>')
def index(fileName, type):
    return auto_scan_image(FILENAME, type)

def showIamge(title, img):
    if DEBUG:
        global DIRPATH, FILENAME, EXTENSION, LOG_INDEX
        LOG_INDEX += 1
        cv2.imwrite(os.path.join(DIRPATH, FILENAME + '_' + str(LOG_INDEX) + '_' + title + EXTENSION), img)
        cv2.namedWindow(title, cv2.WINDOW_NORMAL)
        cv2.imshow(title, img)
        cv2.waitKey()

def auto_scan_image(img, type):
    global DIRPATH, FILENAME, EXTENSION
    DIRPATH = os.path.dirname(img)
    temp = os.path.basename(img)
    FILENAME = os.path.splitext(temp)[0]
    EXTENSION = os.path.splitext(temp)[1]
    
    try:
        image = cv2.imread(img)
        original = image.copy()
    except Exception as e:
        print(f"> {FILENAME} : {e}")
        print(f"> {FILENAME} : {-1}")
        return img
        
    # 1. 가장 큰 외곽의 사각형을 찾아서 바로 세우기 --------------------------------------------------
    r = 1000 / image.shape[0]
    dim = (int(image.shape[1] * r), 1000)
    image = cv2.resize(original, dim, interpolation=cv2.INTER_AREA)

    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (3, 3), 0)
    edged = cv2.Canny(gray, 40, 200)
    
    # 윤곽선 진하게 만드는 코드
    kernel = np.ones((5, 5), np.uint8)
    edged = cv2.dilate(edged, kernel, iterations = 3)
    edged = cv2.erode(edged, kernel, iterations = 3)

    
    (cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    cnts = sorted(cnts, key = cv2.contourArea, reverse=True)
    
    #showIamge("contour", cv2.drawContours(image, [cnts[0]], -1, (0, 255, 0), 3))
    original = setUpright(original, cnts[0], r)
    t = 1000 / original.shape[1]
    dim = (1000, int(original.shape[0] * t))
    original = cv2.resize(original, dim, interpolation = cv2.INTER_AREA)
    haha = original.copy()
    mm = original.copy()

    # 2. 이미지의 평균 칼라 값 계산 --------------------------------------------------------------
    global COLOR_AVG_SUM
    COLOR_AVG_SUM = getColorAvgSum(original)
    print(f"COLOR_AVG_SUM : {COLOR_AVG_SUM}")
    # --------------------------------------------------------------------------------------

    # 2-1. 평균 칼라 값이 기준치 이상으로 밝은 경우 Contrast 상향 조정 ---------------------------------
    if COLOR_AVG_SUM > CONTRAST_COLOR_BASE:
        original = setContrastUp(original)
    # --------------------------------------------------------------------------------------

    # 3. 칼라 양식지 여부 판단 ------------------------------------------------------------------
    #global IS_COLORED_FORMAT
    #IS_COLORED_FORMAT = isColoredFormat(image)

    # 3-1. 칼라 양식지인 경우 칼라 값을 없앰
    #      (칼라 양식지인 경우 글자와 표의 선이 중첩되어 있는 경우가 태반)
    #if IS_COLORED_FORMAT:
    #    original = removeColoredLine(original)
    # --------------------------------------------------------------------------------------

    # 4. 이미지 이진화 ------------------------------------------------------------------------
    original = toBinary(original)
    # --------------------------------------------------------------------------------------
    
    # 5. 이미지 내 표(직선) 없애기 ---------------------------------------------------------------
    original, haha = deTabling(original, haha)
    #showIamge("detabled", original)
    #showIamge("coloring", haha)
    ww = toBinary(haha)
    #ww = cv2.cvtColor(haha, cv2.COLOR_BGR2GRAY)
    #showIamge("ww", ww)
    #ww = cv2.GaussianBlur(ww, (3, 3), 0)
    #showIamge("ww", ww)
    #ww = cv2.Canny(ww, 40, 200)
    #showIamge("ww", ww)
    cnts= cv2.findContours(
        ww, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    #cnts = cnts[0] if len(cnts) == 2 else cnts[1]
    uu = cv2.drawContours(original, cnts[0], -1, (0, 255, 0), 1)
    
    #showIamge("contour", cv2.drawContours(haha, cnts[0], -1, (0, 255, 0), 1))
    cell_li, img_line = detect_cell(cnts[0],mm)
    print(cnts)
    
    result = save_cropCell(cell_li,original,"/Users/kimjw/Desktop/ReadPrescription/crop/")
    
    #showIamge("coloring2", img_line)

    #original = bluring(original)
    # --------------------------------------------------------------------------------------
    
    # 6. 이미지 내 잔존 노이즈(점) 제거 -----------------------------------------------------------
    # original = deNoising(original, type) -- 소숫점이 사라질 수 있음
    # --------------------------------------------------------------------------------------

    # 7. 가로가 1000보타 크면 사이즈 조정 ---------------------------------------------------------
    hei, wid = original.shape
    print(f"> Final Image Size : {wid} * {hei}")

    #if wid > MIN_WIDTH:
    #original = cv2.resize(original, (0, 0), fx=0.25, fy=0.25, interpolation = cv2.INTER_AREA)
    #haha = cv2.resize(haha, dim, interpolation = cv2.INTER_AREA)

    #showIamge("Resize", original)
    # --------------------------------------------------------------------------------------
    
    # 8. 처방전인 경우 Overlay 이미지를 하단에 첨부 ----------------------------------------------
    #if type == '2':
    #    if wid >= 2500:
    #        mov = 1
    #    elif wid >= 2000:
    #        mov = 1
    #    else:
    #        mov = 0

    #    original = prescription(original, mov, haha)
    if type == '3':
        if wid >= 2500:
            mov = 1
        elif wid >= 2000:
            mov = 1
        else:
            mov = 0

        original = detail(original, mov)
    # --------------------------------------------------------------------------------------
    
    cv2.imwrite(os.path.join(DIRPATH, FILENAME + '_useDetectCell' + EXTENSION), img_line)
    cv2.imwrite(os.path.join(DIRPATH, FILENAME + '_boxbox' + EXTENSION), uu)
    
    return FILENAME + '_scanSuccess' + EXTENSION

# Overlay 이미지를 원본과 합치기 위해 배경(흰색)색을 투명하게 변경
def removeBackground(image):
    trans_mask = image[:, :, 0] == 255
    image[trans_mask] = [255, 255, 255, 0]

    return image

def bluring(img):
    kernel = np.ones((5, 5), np.float32)/25
    blur = cv2.filter2D(img, -1, kernel)
    return blur

def overlay(img1, img2):
    rows, cols = img2.shape
    roi = img1[0:rows, 0:cols]

    ret, mask = cv2.threshold(img2, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    mask_inv  = cv2.bitwise_not(mask)

    img1_bg = cv2.bitwise_and(roi, roi, mask = mask_inv)
    img2_fg = cv2.bitwise_and(img2, img2, mask = mask)

    dst = cv2.add(img1_bg, img2_fg)
    img1[0:rows, 0:cols] = dst

    return img1

def order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis = 1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis = 1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect

def deNoising(orig, type):
    #gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)
    thresh = cv2.threshold(orig, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]
    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = cnts[0] if len(cnts) == 2 else cnts[1]
    for c in cnts:
        if cv2.contourArea(c) < 4:
            cv2.drawContours(thresh, [c], -1, (0, 0, 0), -1)

    showIamge("deNoising", ~thresh)
    
    return ~thresh

def deTabling(orig, colo):
    he, wid = orig.shape
    hor = []
    horVer = []
    
    for i in range(0, he):
        chk = 0
        for j in range (0, wid):
            #print(orig[i, j])
            if orig[i, j] == 0:
                colo[i, j] = [255, 255, 255]
                chk = chk + 1
            else:
                colo[i, j] = [255, 255, 255]
                if chk >= 25:
                    for t in range(j - chk, j):
                        colo[i, t] = [0, 0, 255]
                    #    hor.insert(0, [i, t])
                chk = 0
    for i in range(0, wid):
        chk = 0
        for j in range (0, he):
            #print(orig[i, j])
            if orig[j, i] == 0:
                chk = chk + 1
            else:
                if chk >= 28:
                    for t in range(j - chk, j):
                        colo[t, i] = [0, 0, 255]
                        itq = [t, i]
                        #if itq in hor:
                        #    horVer.insert(0, itq)
                        #    colo[t, i] = [255, 0, 0]
                chk = 0
    print(horVer)
            
    thresh = cv2.threshold(orig, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]
    # Remove horizontal
    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 1))
    detected_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=4)
    cnts = cv2.findContours(detected_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = cnts[0] if len(cnts) == 2 else cnts[1]
    for c in cnts:
        cv2.drawContours(orig, [c], -1, (255, 255, 255), 3)

    # Remove vertical
    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 20))
    detected_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, vertical_kernel, iterations=4)
    cnts = cv2.findContours(detected_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = cnts[0] if len(cnts) == 2 else cnts[1]
    for c in cnts:
        cv2.drawContours(orig, [c], -1, (255, 255, 255), 3)

    return orig, colo

def angle_cos(p0, p1, p2):
    d1, d2 = (p0-p1).astype('float'), (p2-p1).astype('float')
    return abs(np.dot(d1, d2) / np.sqrt(np.dot(d1, d1)*np.dot(d2, d2)))

def setUpright(image, screenCnt, r):

    peri = cv2.arcLength(screenCnt, True)
    approx = cv2.approxPolyDP(screenCnt, 0.02 * peri, True)

    if len(approx) < 4:
        return image


    s = sorted(approx, key = lambda x : (x[0][0] + x[0][1]))
    s1 = sorted(approx, key = lambda x : (x[0][1] - x[0][0]))
    print(f"> sorted approx : {s} {len(s)}")

    n = np.zeros((4, 1, 2), dtype=np.int64)

    n[0] = s[0]
    n[1] = s1[0]
    n[2] = s[len(s)-1]
    n[3] = s1[len(s1)-1]

    print(f"> n : {n[0]}, {n[1]}, {n[2]}, {n[3]}")
    t1 = np.sqrt(np.square(n[2][0][0] - n[0][0][0]) + np.square(n[2][0][1] - n[0][0][1]))
    t2 = np.sqrt(np.square(n[3][0][0] - n[1][0][0]) + np.square(n[3][0][1] - n[1][0][1]))
    if np.abs(t1 - t2) > 50:
        print(f"대각선 안맞음 {t1} {t2}")
        return image

    rect = order_points(n.reshape(4, 2) / r)
    (topLeft, topRight, bottomRight, bottomLeft) = rect
    print(f"rect {topLeft} {topRight} {bottomRight} {bottomLeft}")

    w1 = abs(bottomRight[0] - bottomLeft[0])
    w2 = abs(topRight[0] - topLeft[0])
    h1 = abs(topRight[1] - bottomRight[1])
    h2 = abs(topLeft[1] - bottomLeft[1])
    maxWidth  = max([w1, w2])
    maxHeight = max([h1, h2])
    
    dst = np.float32([[0, 0],
                      [maxWidth-1, 0],
                      [maxWidth-1, maxHeight-1],
                      [0, maxHeight-1]])
    
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))

    return warped

def toBinary(image):
    orig = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    if IS_COLORED_FORMAT == False:
        orig = cv2.adaptiveThreshold(orig, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 5)
    else:
        orig = cv2.adaptiveThreshold(orig, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 30)

    #showIamge('toBinary', orig)
    
    orig = unsharp_mask(orig)

    return orig

def unsharp_mask(image, kernel_size=(5, 5), sigma=1.0, amount=1.0, threshold=0):
    """Return a sharpened version of the image, using an unsharp mask."""
    blurred = cv2.GaussianBlur(image, kernel_size, sigma)
    sharpened = float(amount + 1) * image - float(amount) * blurred
    sharpened = np.maximum(sharpened, np.zeros(sharpened.shape))
    sharpened = np.minimum(sharpened, 255 * np.ones(sharpened.shape))
    sharpened = sharpened.round().astype(np.uint8)
    if threshold > 0:
        low_contrast_mask = np.absolute(image - blurred) < threshold
        np.copyto(sharpened, image, where=low_contrast_mask)

    #showIamge('unsharp_mask', sharpened)

    return sharpened

def prescription(original, mov, haha):
    t = original.copy()
    if mov == 2:
        aff = np.array([[1, 0, 30], [0, 1, 0]], dtype=np.float32)
    elif mov == 1:
        aff = np.array([[1, 0, 20], [0, 1, 0]], dtype=np.float32)
    else:
        aff = np.array([[1, 0, 15], [0, 1, 0]], dtype=np.float32)
    img2 = cv2.warpAffine(original, aff, (0, 0))
    dst = overlay(original, img2)
    dst = cv2.cvtColor(dst, cv2.COLOR_GRAY2BGR)
    res = cv2.vconcat([haha, dst])
    return res
    
def detail(original, mov):
    t = original.copy()
    if mov == 2:
        aff = np.array([[1, 0, 30], [0, 1, 0]], dtype=np.float32)
    elif mov == 1:
        aff = np.array([[1, 0, 20], [0, 1, 0]], dtype=np.float32)
    else:
        aff = np.array([[1, 0, 15], [0, 1, 0]], dtype=np.float32)
    img2 = cv2.warpAffine(original, aff, (0, 0))
    dst = overlay(original, img2)
    res = cv2.vconcat([t, dst])
    return res

def isColoredFormat(img):

    height, width, channels = img.shape
    size = height * width

    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, LOWER_RANGE, UPPER_RANGE)
    color = cv2.countNonZero(mask)
    print(f"> Color Count : {color}")

    if color >= COLORED_PIXEL_COUNT:
        return True

    return False

# 가장 많이 사용된 색깔 찾기
def getDominantColor(img):

    data = np.reshape(img, (-1, 3))
    
    data = np.float32(data)

    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
    flags = cv2.KMEANS_RANDOM_CENTERS
    compactness, labels, centers = cv2.kmeans(data, 1, None, criteria, 10, flags)

    print(f"> Dominant color is: bgr({centers[0].astype(np.int32)})")

    return centers[0].astype(np.int32)

def removeColoredLine(image):
    
    if IS_COLORED_FORMAT == False:
        return image

    print(f"> colorAvgSum : {COLOR_AVG_SUM}")
    
    # 양식지의 표 색깔 및 채도, 명도에 따라 다른 값을 적용해야 표를 없앨 수 있음
    if COLOR_AVG_SUM >= 720:
        lower_range2 = np.array([90,   10, 100])
        upper_range2 = np.array([150, 255, 255])
    elif COLOR_AVG_SUM >= 600:
        lower_range2 = np.array([90,   10, 100])
        upper_range2 = np.array([150, 255, 255])
    elif COLOR_AVG_SUM >= 480:
        lower_range2 = np.array([80,   0,   65])
        upper_range2 = np.array([150, 255, 255])
    else:
        lower_range2 = np.array([90,   10, 100])
        upper_range2 = np.array([150, 255, 255])

    dominantColor = getDominantColor(image)
    #dominantColor = (0, 0, 255)
    print(f"> dominantColor : {dominantColor}")

    height, width, channels = image.shape
    half_line = np.int64(height / 2)

    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Remove horizontal lines
    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))
    remove_horizontal = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)
    cnts = cv2.findContours(remove_horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = cnts[0] if len(cnts) == 2 else cnts[1]

    # result = image.copy()
    # for c in cnts:
    #     cv2.drawContours(result, [c], -1, (0, 0, 255), 3)
    # showIamge('drawContours', result)

    # 처방전 상의 "처방 의약품의 명칭"이라는 라벨의 바로 아래에 있는 실선의 위치
    # 아래의 의약품
    min_y_half_up = 0
    line_array = []
    for c in cnts:
        for cc in [c][0]:
            t = cc[0][1]
            line_array.append(t)
            if t < half_line:
                if min_y_half_up < t:
                    min_y_half_up = t
    
    line_array = np.unique(line_array)

    print(f"> half_line : {half_line}, min_y_half_up : {min_y_half_up}, len(line_array) : {len(line_array)}")

    # min_y_half_up 위의 파란색 선 처리용 이미지
    image1 = image.copy()
    height, width, channels = image1.shape
    hsv1 = cv2.cvtColor(image1, cv2.COLOR_BGR2HSV)

    # 라인들 중 파란색 계열만 배경색으로 변경
    for row in line_array:
        # print("> row : ", row)
        if row <= min_y_half_up:
            for col in range(100, width-1):
                for rr in range(row-2, row+2):
                    if rr >= 0 and rr < height:
                        if hsv1.item(rr, col, 0) in range(lower_range2[0], upper_range2[0]) and \
                           hsv1.item(rr, col, 1) in range(lower_range2[1], upper_range2[1]) and \
                           hsv1.item(rr, col, 2) in range(lower_range2[2], upper_range2[2]):
                            image1.itemset(rr, col, 0, dominantColor[0])
                            image1.itemset(rr, col, 1, dominantColor[1])
                            image1.itemset(rr, col, 2, dominantColor[2])
    
    image1_roi = image1[0:min_y_half_up, 0:width-1]

    # min_y_half_up 아래의 파란색 선 처리용 이미지
    image2 = image.copy()
    hsv2 = cv2.cvtColor(image2, cv2.COLOR_BGR2HSV)
    mask2 = cv2.inRange(hsv2, lower_range2, upper_range2)
    image2[mask2 > 0] = dominantColor

    image2[0:min_y_half_up, 0:width-1] = image1_roi

    showIamge('removeColoredLine', image2)

    return image2

def getColorAvgSum(img):
    avg_colors = np.average(np.average(img, axis=0), axis=0)

    avg = int(avg_colors[0]) + int(avg_colors[1]) + int(avg_colors[2])
    print(f"Average Color : {avg} = {int(avg_colors[0])} + {int(avg_colors[1])} + {int(avg_colors[2])}")

    return avg

def setContrastUp(input_img, brightness=-64, contrast=64):
    
    if brightness != 0:
        if brightness > 0:
            shadow = brightness
            highlight = 255
        else:
            shadow = 0
            highlight = 255 + brightness
        alpha_b = (highlight - shadow) / 255
        gamma_b = shadow
        
        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)
    else:
        buf = input_img.copy()
    
    if contrast != 0:
        f = 131 * (contrast + 127) / (127 * (131 - contrast))
        alpha_c = f
        gamma_c = 127 * (1 - f)
        
        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)

    showIamge('setContrastUp', buf)

    return buf

def detect_cell(cnts,img):
    
    image_copy = img.copy()
   
    im_w,im_h,_ = image_copy.shape
    img_area = im_w * im_h
    
    cell_li = []
    #box_li = []
    
    for cnt in cnts:
    
        x, y, w, h = cv2.boundingRect(cnt)
        area = cv2.contourArea(cnt)
        

        
        if area > img_area * 0.8:
            continue
        
        if area > 200 and h > 18 and w > 8:
        
        # 글자 높이보다는 h가 커야 됨
        # TODO : 평균 글자 높이 잡아서 그거보다 크게 만듬
        
            
            rect = cv2.minAreaRect(cnt)
            box_point = cv2.boxPoints(rect)
            point = order_points(box_point)
            
            # 삐뚤어진 이미지 제거
            if 8 < abs(point[0][1] - point[1][1]):
           
                continue
            
            if len(box_point) <4 :
                
                print(len(box_point))
                continue
                #box = np.int0(box)
                #box_li.append(box)
                
            cell_li.append([x,y,w,h])
            cv2.drawContours(image_copy,[box_point.astype(int)],0,(255,0,0),1)
        
    

    #showIamge("drawContours", image_copy)
    
    
    return cell_li , image_copy

def save_cropCell(cell,ori_img,save_path):
    
    
    
    save_path = os.path.join(save_path, 'IMG_')
        
    w,h = ori_img.shape
    
    mask = np.zeros((w, h))
    
    count=0
    for x,y,w,h in cell:
        
        count = count+1
        mask[y: y + h, x: x + w] = 255
        
        cv2.imwrite(save_path+str(count)+".jpg", ori_img[y: y + h, x: x + w])
        
    
    mask = (mask*1).astype('uint8')
    masked = cv2.bitwise_and(ori_img,ori_img, mask =mask)
    
    
    #showIamge("setUpright", masked)
    
    
    
    return masked

####################################################################################
#if DEBUG:
t, img, type = argv
#else:
#    t, port,  = argv

if __name__ == '__main__':
    #if DEBUG:
    start = time.time()
    auto_scan_image(img, type)
    print("time :", time.time() - start)
    #else:
        #run(host='localhost', port=port)
####################################################################################
